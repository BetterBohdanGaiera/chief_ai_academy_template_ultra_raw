# F2: Organization Structure

**Course:** Foundation
**Duration:** 18 minutes
**Prerequisites:** F1 (Five Levels Framework)

## Why This Matters

Understanding the 5 Levels Framework shows you WHERE transformation happens. But knowing where isn't enough—you need to know WHO makes it happen and HOW they work together.

Level 4 transformation doesn't happen by accident. It requires specific roles working in specific ways. The Agent Manager + Developer partnership is what enables the rapid iteration (10-20 cycles/day) that defines Level 4.

This module shows you:
- The four key roles needed for transformation
- How these roles work together through real process stories
- The transformation timeline and process
- Who you have vs who you need

## Learning Objectives

By the end of this module, you will be able to:
1. Name the four key roles in AI transformation and their responsibilities
2. Explain why the Agent Manager role is critical for Level 4 success
3. Describe how Agent Manager + Developer partnership enables rapid iteration
4. See the pattern of transformation through HR, Sales, and Operations stories
5. Assess your organization's role gaps
6. Understand realistic transformation timeline and process

## Connection to Bigger Picture

In F1, you learned that Level 4 is defined by rapid iteration (10-20 cycles/day vs 1-2/month). This module shows you the organizational structure that makes that rapid iteration possible. Without these roles working together, you can't reach Level 4—no matter what technology you use.

---

## Content

### 1. Four Key Roles in AI Transformation

**Strategic Leadership:**
- **Chief AI Officer** - Company-wide strategy & resource allocation

**Department Leadership:**
- **AI Champions** - One per department, lead transformation in their area

**Operational Execution:**
- **Agent Managers** - Process experts who prepare context for AI
- **AI Agent Developers** - Technical builders who implement agents

**Critical Partnership:** Agent Manager + AI Agent Developer = Success

**Key Insight:** Most roles filled by existing employees, not new hires

---

### 2. Chief AI Officer - Strategic Leadership

**Scope:** Company-wide transformation

**Responsibilities:**
- Set AI strategy and transformation roadmap
- Decide: ML vs Agentic vs ready-made tools
- Allocate budget & resources across departments
- Report ROI to CEO and board
- Own company-wide transformation success

**Who Fills This Role:**
- Existing C-suite executive (CTO, COO, Chief Innovation Officer)
- New hire if company is serious about transformation

**Time Commitment:** Strategic oversight, not day-to-day execution

**Key Characteristic:** Drives transformation from top, enables department leaders

---

### 3. AI Champion - Department Leadership

**Scope:** One per department (HR, Sales, Marketing, Engineering, etc.)

**Responsibilities:**
- Lead AI transformation in their department
- Identify use cases and prioritize them
- Advocate for adoption within department
- Measure department-level ROI
- Report progress to Chief AI Officer

**Who Fills This Role:**
- Department heads or senior managers
- People who understand department processes deeply
- Strong communicators who can evangelize change

**Time Commitment:**
- At first: Often 10-20% time (role, not job)
- As transformation scales: May become full-time

**Key Characteristic:** Leadership role, not technical role

---

### 4. Agent Manager - The Critical Role

**Scope:** One per process/use case

**Responsibilities:**
- Document process step-by-step (what, when, why)
- Prepare context for AI (context engineering)
- Identify knowledge sources (docs, systems, people)
- Validate AI outputs (is it correct? useful?)
- Maintain knowledge over time

**Why Agent Manager is Critical for Level 4 Success:**

The Agent Manager role enables rapid iteration through direct partnership with developers:

**What Agent Manager Brings:**
- **Domain expertise** integrated into the team (not external)
- **Direct collaboration** with AI Agent Developer (no communication barriers)
- **Immediate validation** of outputs (minutes, not weeks)
- **Tacit knowledge extraction** through rapid iteration (show result → identify gap → adjust)
- **AI capability learning** through developer partnership
- **Sustained iteration capability** throughout the process

**This role enables:**
- Production systems that handle real complexity
- 10-20 iterations per day (not 1-2 per month)
- 95%+ reliability through continuous refinement

**Who Fills This Role:**
- Process experts from existing teams (NOT developers)
- People who know the process best
- Examples: Senior HR specialist, top sales rep, senior PM

**Time Commitment:**
- During build (6-10 weeks): 50-70% time
- After launch: 10-20% time for maintenance

**Key Characteristic:** This role makes or breaks transformation

**What They Are NOT:** ❌ Developers | ❌ Data scientists | ❌ Project managers
**What They ARE:** ✅ Process experts | ✅ Knowledge architects | ✅ Quality validators

---

### 5. AI Agent Developer - Technical Builder

**Scope:** Technical implementation across multiple use cases

**Responsibilities:**
- Build AI agents using context from Agent Manager
- Integrate systems (CRM, databases, APIs)
- Implement workflows and orchestration
- Optimize performance and handle edge cases
- Maintain technical infrastructure

**Who Fills This Role:**
- Software developers (existing or new hires)
- Must learn agentic architecture (2-4 weeks upskilling)
- Experience with APIs, Python/JavaScript helpful

**Time Commitment:** Full-time role

**Key Characteristic:** Success depends on partnership with Agent Manager

---

### 6. The Critical Partnership - THIS IS LEVEL 4

**The Magic Formula:**

Agent Manager (process expert) + AI Agent Developer (technical expert) Co-Located = **Rapid Feedback Loops** = Level 4 Iterative Agents

**THIS PARTNERSHIP STRUCTURE IS WHAT CREATES LEVEL 4.**

| What | Agent Manager | AI Agent Developer |
|------|---------------|-------------------|
| **Knows the process** | ✅ Deep expertise | ❌ Learning from scratch |
| **Knows the context** | ✅ All edge cases | ❌ Doesn't have years of experience |
| **Can build the agent** | ❌ Not technical | ✅ Technical skills |
| **Can validate outputs** | ✅ Spots mistakes immediately | ❌ Doesn't know what's correct |

**Agent Manager brings:** Process knowledge + Context + Validation capability
**Developer brings:** Technical ability to build and deploy
**Together:** Technically sound AND process-accurate agent

**Why This Partnership Enables Level 4:**

**Agent Manager (Domain Expert) + AI Agent Developer Co-Located = RAPID ITERATION**

**This 10-20 iterations per DAY IS what Level 4 means:**
- Domain expert and developer sit together (or tightly coordinated remotely)
- **Feedback cycle costs MINUTES** (not weeks + $$$):
  - Developer builds feature (30 min) → Agent Manager tests (10 min) → Sees problem → Explains context (5 min) → Developer fixes (20 min)
  - **This cycle happens 10-20 times per DAY** during active development
- **200+ total iterations** over 6-10 weeks (vs 3-5 iterations with agencies)
- Domain expertise extracted through rapid feedback, not upfront documentation
- Agent Manager learns AI capabilities from developer partnership
- Developer understands edge cases from Agent Manager feedback
- Result: Production-grade system that handles real complexity (95%+ reliability, not 70%)

**Timeline Comparison:**

| Approach | Build Time | Iteration Speed | Outcome |
|----------|-----------|----------------|----------|
| **Level 3 (No-Code/External)** | 6 weeks | 1-2 weeks per change | POC → 6 months debugging → Often abandoned |
| **Level 4 Partnership** | 6-10 weeks | Minutes per iteration | Production-ready with ongoing improvement |

**The Secret of Level 4:** It's not about avoiding iteration - it's about making iteration FAST and CHEAP. This partnership structure enables the 200+ iterations needed to reach true reliability through rapid feedback loops.

---

## ROLES IN ACTION: Three Process Stories

### 7. Story 1 - HR Onboarding Assistant

**The Team:**
- **Sarah (Agent Manager)**: HR Director, 8 years experience, knows every edge case in onboarding
- **Marcus (AI Agent Developer)**: Software engineer, 3 years experience, understands AI + integrations
- **AI Champion**: VP of People Operations, sponsors the project

**Week 1: Initial Requirements**

Marcus: "Walk me through your ideal onboarding process. What information do new hires need?"

Sarah: "They need to know our benefits, PTO policy, how to request equipment, who to contact for IT issues, and... actually, there's a lot. Let me share our policy docs."

Marcus: "Perfect. Let me build a first version that can answer questions from these docs. I'll have something for you to test by tomorrow."

**The Rapid Iteration Begins...**

**Day 2: First Test (5 iterations in one day)**

Sarah tests the first version:

**Test 1:** "What's our PTO policy for new employees?"
**Agent:** "Employees receive 15 days PTO per year."
**Sarah:** ❌ "That's incomplete. New employees are on probation for 90 days and can't take PTO during that time. Also, PTO accrual is different for part-time employees."

Marcus: "Got it. Let me update the context to include probation period rules and part-time distinctions."
*[15 minutes later]*
Marcus: "Try again."

**Test 2:** "What's our PTO policy for new employees?"
**Agent:** "New employees must complete 90-day probation before taking PTO. Full-time employees receive 15 days/year."
**Sarah:** ✓ "Better! But it should mention that PTO requests during holidays require 2-week advance notice, not the usual 3-day notice."

Marcus: "Adding that now."
*[10 minutes later]*

**This continues... 5 complete iterations in one afternoon.**

**Key Insight:** Sarah sees results immediately, extracts tacit knowledge through iteration, no external dependencies

**Week 2: Discovering Hidden Complexity (40 more iterations)**

Sarah tests edge cases:

**Test 23:** "I'm relocating from our Austin office to the Seattle office. What do I need to do?"
**Agent:** "Please contact HR to discuss relocation procedures."
**Sarah:** ❌ "Way too generic! It should explain the relocation reimbursement policy, mention that relocations require manager approval, note the different state tax implications, and provide the relocation request form link."

Marcus: "I didn't know we had a relocation policy!"
**Sarah:** "Exactly. It's not in the general onboarding docs. It's buried in a separate operations manual. Let me find it..."

**The Hidden Knowledge Problem:**

Sarah realizes she knows hundreds of these edge cases from 8 years of experience:
- International employee work permits
- Contractor vs employee benefit differences
- Remote work equipment policies by state
- COBRA eligibility rules for part-time employees
- Dependent care FSA enrollment deadlines

**She couldn't document all this upfront - it emerged through testing real scenarios.**

Marcus and Sarah meet for 30 minutes:
- Sarah explains 10 more scenarios
- Marcus updates the agent's context
- They immediately test the changes
- 8 out of 10 work perfectly, 2 need refinement
- They refine those 2 on the spot

**This 30-minute cycle repeats 3-4 times per week.**

**Iteration count after Week 2: 45 total iterations**

**Week 6: Final Refinements**

**Total Iteration Count: 200+**

**Result After 6 Weeks:**
- ✓ **Coverage**: 95% of onboarding questions answered correctly
- ✓ **Quality**: Matches or exceeds human HR specialist responses
- ✓ **Speed**: 3-second response time vs 2-hour human response time
- ✓ **Consistency**: Same high-quality answer every time
- ✓ **Availability**: 24/7 access for employees in different time zones

**ROI:**
- **Investment**: $45K (Marcus's 6 weeks + infrastructure)
- **Value**: $99K/year (250 hours saved annually + higher employee satisfaction)
- **Payback**: 5 months
- **Net ROI**: $54K/year ongoing

**The Partnership That Made It Work:**

**Sarah (Agent Manager) brought:**
- 8 years of HR domain expertise
- Knowledge of every edge case and exception
- Understanding of what "good" responses look like
- Ability to validate outputs immediately

**Marcus (Developer) brought:**
- Technical ability to build and iterate quickly
- AI expertise to structure context effectively
- Integration skills to connect systems
- Speed: 15-minute iteration cycles (not weeks)

**Together they achieved:**
- **200+ iterations in 6 weeks** (vs 3-5 with external agency)
- **10-20 iterations per day** on active days
- **95%+ reliability** (vs 70% with Level 3 approach)
- **Deep integration** with company knowledge (not shallow)

**This is the Level 4 defining structure**: Co-located expert + builder enabling rapid feedback.

---

### 8. Story 2 - Sales Call Analyzer

**The Team:**
- **David (Agent Manager)**: Sales Director, 12 years in B2B SaaS sales, knows winning vs losing call patterns
- **Priya (AI Agent Developer)**: Software engineer, understands LLMs + speech-to-text APIs
- **AI Champion**: VP of Sales, wants to scale David's coaching across 40-person team

**Week 1: The Initial Vision**

David: "Our reps record sales calls but don't review them systematically. I can listen and spot what's working - discovery questions, objection handling, closing technique. But I can only review 5-10 calls per week. We do 200+ calls weekly."

Priya: "So you want AI to analyze calls using YOUR evaluation criteria?"

David: "Exactly. If it can spot the patterns I look for, I can coach the whole team, not just the few calls I have time to review."

**Week 2: Discovering Sales Methodology Is Hard to Document (30 iterations)**

Priya builds first version. David tests with real call transcripts.

**Test 5:** *Call where rep asked 8 discovery questions*
**Agent:** "Strong discovery: 8 questions asked."
**David:** ❌ "Not just the number - it's the QUALITY. Good discovery questions are open-ended and build on previous answers. This rep asked 8 yes/no questions, which is weak discovery."

Priya: "So I need to evaluate question quality, not just count?"
David: "Yes. Open-ended questions like 'Tell me about your current process' are strong. Closed questions like 'Do you have a budget?' are weak."

Priya: "Got it. Let me add that logic."
*[20 minutes later]*

**Test 6:** *Same call*
**Agent:** "Weak discovery: 8 questions asked, but 7 were closed yes/no questions. Only 1 open-ended question."
**David:** ✓ "Now you're seeing what I see!"

**Weeks 3-4: Rapid Iteration Through Real Examples (60 iterations)**

David and Priya establish a new workflow:

**Every Tuesday and Thursday afternoon (2 hours each):**
1. David selects 5 recent calls (mix of strong/weak examples)
2. Priya runs them through the agent
3. David reviews agent analysis vs his own assessment
4. They discuss discrepancies for 30 minutes
5. Priya updates the evaluation criteria immediately
6. They re-test the same calls
7. Repeat 8-10 times per session

**Total Iteration Count: 200+**

**Result After 8 Weeks:**
- ✓ **Accuracy**: 92% alignment with David's manual scoring
- ✓ **Coverage**: Analyzes all 200+ weekly calls (vs David's 5-10)
- ✓ **Speed**: Analysis available within 24 hours of call completion
- ✓ **Coaching**: Generates specific coaching recommendations per rep
- ✓ **Insight**: Identifies patterns David couldn't see manually

**ROI:**
- **Investment**: $52K (Priya's 8 weeks + speech-to-text API + infrastructure)
- **Value**: $180K/year (team performance improvement + David's coaching time reclaimed)
- **Payback**: 3.5 months
- **Net ROI**: $128K/year ongoing

**The Discovery That Made It Work:**

David couldn't document his sales methodology upfront - it was tacit knowledge built over 12 years.

**The knowledge emerged through iteration:**
- Test calls → Spot discrepancies → Explain WHY agent was wrong → Update criteria → Re-test

Priya's speed enabled this:
- 15-minute iteration cycles (not weeks)
- Immediate re-testing after changes
- Both in the same room (no communication delays)

After 200+ iterations, the agent "learned" David's expertise - not through training data, but through structured context refinement.

**This is why Level 4 requires co-located teams enabling rapid feedback.**

---

### 9. Story 3 - Vendor SLA Compliance Tracker

**The Team:**
- **Jennifer (Agent Manager)**: Operations Manager, 10 years managing vendor relationships
- **Alex (AI Agent Developer)**: Software engineer, experience with APIs and data integration
- **AI Champion**: COO, wants better vendor accountability

**Week 1: The Challenge**

Jennifer: "We have 40+ vendors with different SLA commitments. I track them manually in spreadsheets. It takes 8 hours per week and I still miss violations because data is scattered across systems."

Alex: "What systems have the data?"

Jennifer: "Incident management (Jira), support tickets (Zendesk), invoices (accounting system), contract PDFs (shared drive). Each vendor's SLA is different - some measure response time, others uptime, others ticket resolution time."

**Week 2: Policy Complexity Emerges (25 iterations)**

Alex builds first version for Vendor A (cloud hosting provider).

**Test 3:**
**Agent:** "Vendor A SLA: 99.9% uptime. Current: 99.7%. Status: VIOLATION."
**Jennifer:** ❌ "Not quite. Their contract allows 'scheduled maintenance windows' that don't count against uptime. Last month's downtime was scheduled maintenance, so they're actually compliant."

Alex: "Where's that documented?"
Jennifer: "Page 17 of the contract, Section 4.2.3. Oh, and 'scheduled' means 7-day advance notice via email."

Alex: *[reads contract]* "This is complex! There are like 10 exceptions and special conditions."
Jennifer: "Welcome to vendor contracts. They're all like this."

**Weeks 3-4: Synthesizing Multiple Vendor Policies (50 iterations)**

Jennifer and Alex tackle 5 more vendors. Each has unique SLA terms:

**Vendor B (Support ticketing system):**
- SLA: 90% of P1 tickets resolved within 4 hours
- BUT: "Resolution" means "workaround provided," not "fully fixed"
- AND: Tickets opened during weekends don't count toward 4-hour clock until Monday 9am
- EXCEPTION: If customer delays response, clock pauses

**Total Iteration Count: 200+**

**Result After 7 Weeks:**
- ✓ **Coverage**: 40 vendors monitored automatically (vs Jennifer's manual 12-vendor subset)
- ✓ **Accuracy**: 96% correct SLA compliance assessment
- ✓ **Speed**: Real-time monitoring vs weekly manual review
- ✓ **Actionable**: Specific recommendations with contract references and dollar amounts
- ✓ **Proactive**: Flags renewal opportunities 6 months ahead with negotiation leverage

**ROI:**
- **Investment**: $48K (Alex's 7 weeks + infrastructure)
- **Value**: $120K/year (Jennifer's time reclaimed + $35K in penalty recoveries + better vendor negotiation leverage)
- **Payback**: 4.8 months
- **Net ROI**: $72K/year ongoing

**The Hidden Complexity That Required Iteration:**

Jennifer thought she could "just document the SLA terms."

But through testing she discovered:
- 10+ exception clauses per contract
- Complex time calculations (weekends, holidays, maintenance windows)
- Force majeure conditions
- Customer-caused delays
- Different resolution definitions per vendor
- Penalty clauses tied to violation counts
- Renewal timing triggers

**This knowledge couldn't be documented upfront - it emerged through real scenario testing.**

Alex's rapid iteration enabled discovery:
- Test scenario → Agent gets it wrong → Jennifer explains the rule → Alex updates context → Re-test in 15 minutes

After 200+ iterations across 7 weeks, they captured 10 years of Jennifer's operational knowledge.

**This is the power of co-located rapid feedback.**

---

### 10. The Pattern Across All Three Stories

**What These Three Stories Teach Us**

**The Universal Pattern:**

| Element | HR Story | Sales Story | Operations Story |
|---------|----------|-------------|------------------|
| **Agent Manager** | Sarah (HR Director, 8 years) | David (Sales Director, 12 years) | Jennifer (Ops Manager, 10 years) |
| **Domain Expertise** | HR policies, edge cases | Sales methodology, call patterns | Vendor contracts, SLA terms |
| **Developer** | Marcus (3 years) | Priya (ML + API experience) | Alex (APIs + data integration) |
| **Timeline** | 6 weeks | 8 weeks | 7 weeks |
| **Iteration Count** | 200+ | 200+ | 200+ |
| **Iterations Per Day** | 10-20 on active days | 8-10 on active days | 8-12 on active days |
| **Hidden Complexity** | Probation rules, relocation policies, benefit scenarios | Indirect qualification, story-based selling, scoring weights | Contract exceptions, force majeure, penalty clauses |
| **Key Discovery** | Couldn't document upfront, emerged through testing | Tacit knowledge extracted through iteration | 10 years of operational nuance captured |
| **Final Reliability** | 95% coverage | 92% alignment with expert | 96% accuracy |
| **ROI** | $54K/year | $128K/year | $72K/year |

**What Made Level 4 Work in All Three Cases:**

**1. Co-Located Teams**
- Agent Manager + Developer in same room (or daily calls)
- No external agency delays
- Immediate feedback loops

**2. Rapid Iteration Capability**
- 15-minute iteration cycles (not weeks)
- Test → Identify issue → Fix → Re-test → Repeat
- Iteration cost in MINUTES, not $$$ and weeks

**3. Domain Expertise Extraction**
- Hidden knowledge emerged through testing, not upfront documentation
- "Bad" results revealed tacit knowledge
- Each iteration captured years of experience

**4. Continuous Improvement**
- Started at 60-70% accuracy
- Reached 95%+ through iteration volume
- 200+ iterations to transform prototype → reliable system

**5. Validation Authority**
- Agent Manager could immediately say "This is right" or "This is wrong"
- No multi-week approval cycles
- Real-time quality validation

**Why External Agencies Can't Replicate This:**

**Level 3 Agency Approach:**
- Initial build: 6 weeks
- Domain expert tests → Emails feedback to agency
- Agency schedules meeting (1 week later)
- Explains changes needed → Lost context
- Agency makes changes → Delivers new version (2 weeks)
- **Result**: 1-2 iterations per MONTH → Only 3-5 total → Stuck at 70% → Often abandoned

**Level 4 Internal Approach:**
- Initial build: 1-2 weeks
- Domain expert tests → Walks to developer's desk
- Explains issue → Developer understands immediately
- Developer fixes → Re-test in 15 minutes
- **Result**: 10-20 iterations per DAY → 200+ total → Reaches 95%+ → Production-ready

**The difference is the COST and SPEED of feedback:**
- Agency: WEEKS + $$$ per iteration
- Internal: MINUTES + $0 per iteration

**This is why transformation requires internal teams.**

---

### 11. Transformation Process - Three Phases

Now that you understand the roles and how they work together, here's the step-by-step playbook for transformation:

**Phase 1: Build AI Strategy** | 2-4 weeks
- Assess current state (which level?)
- Create roadmap (which use cases, what order)
- Define roles (Champions, Agent Managers, Developers)
- Plan context engineering

**Outputs**: Roadmap | Priority list | Role assignments | Budget

**Phase 2: Train Team** | 1-3 months (concurrent)
- AI Champions: 2-3 days intensive
- Agent Managers: 1-3 months hands-on
- AI Agent Developers: Technical training

**Note**: Runs parallel with Phase 1 and early Phase 3

**Phase 3: Execute & Scale** | 6-10 weeks per use case
- Start with ONE use case (quick win)
- 6-10 weeks implementation
- Measure ROI
- Build momentum → Scale

**Timeline:**
- First Results: 6-10 weeks
- Full Transformation: 12-18 months to Level 4-5

**Budget:**
- Single use case: $30-50K initial | $5-10K/year
- Payback: 1-3 months per use case

---

### 12. Team Size - What You Actually Need

**To Start (First Use Case):**

| Role | Headcount | Notes |
|------|-----------|-------|
| Chief AI Officer | 1 (existing) | Strategic oversight |
| AI Champion | 1 (existing) | Department lead, part-time at first |
| Agent Manager | 1 (existing) | Process expert, 50% time during build |
| AI Agent Developer | 1-2 | Can be existing devs or new hire |

**Total new hires needed: 0-1** (maybe one developer if team lacks capacity)

**To Scale:**

**Year 1 (4-6 use cases):**
- 1 Chief AI Officer
- 3-4 AI Champions (one per department)
- 4-6 Agent Managers (one per use case, existing team members)
- 2-3 AI Agent Developers

**Year 2 (10-15 use cases):**
- 1 Chief AI Officer
- 6-8 AI Champions
- 10-15 Agent Managers
- 4-6 AI Agent Developers

**Key Insight:** Most Agent Managers are existing employees in new roles, not new hires

---

## Summary

1. **Four key roles**: Chief AI Officer, AI Champions, Agent Managers, AI Agent Developers
2. **Agent Manager is the most critical role**: They bridge business knowledge and technical implementation
3. **The critical partnership**: Agent Manager (process expert) + Developer (technical expert) = Level 4
4. **Partnership enables rapid iteration**: 10-20 iterations per day (not 1-2 per month)
5. **Hidden complexity emerges through iteration**: Domain experts can't document all knowledge upfront
6. **200+ iterations transform 70% prototypes into 95%+ reliable systems**: Volume of iteration separates Level 4 from Level 3
7. **Pattern is universal across domains**: HR, Sales, Operations all followed same approach
8. **6-8 weeks to production-ready**: Realistic timeline when feedback loops are fast and cheap
9. **ROI consistently strong**: $45-52K investment → $70-130K/year value → 3-5 month payback
10. **External agencies can't replicate this**: 1-2 iterations/month vs 10-20/day - the economics don't work
11. **Three-phase transformation**: Strategy (2-4 weeks) → Train (1-3 months) → Execute (6-10 weeks per use case)
12. **Most roles filled by existing employees**: You don't need 20 new hires to start

---

## Interactive Wrap-Up: Who Do You Have? Who Do You Need?

**Assess your organization:**

**Chief AI Officer:**
□ Do you have executive leadership committed to AI transformation?
□ Who would own company-wide AI strategy?

**AI Champions:**
□ Which department heads are interested in AI?
□ Who has the influence to drive adoption in their area?

**Agent Managers:**
□ Who are your process experts with 5+ years domain expertise?
□ Who can articulate what "good" vs "bad" outputs look like?
□ Who knows the edge cases in their processes?

**AI Agent Developers:**
□ Do you have developers who can learn agentic architecture?
□ Do you need to hire 1-2 developers to start?

**Key Message:**
- You likely have more talent than you think
- Most roles are existing employees in new capacities
- Start with 1-2 developers + existing domain experts
- Scale gradually as you prove value

---

## What's Next

**If you're an Executive:** → Recommended: S1 (Choosing AI Technology) to understand tech decisions
**If you're an AI Champion:** → Recommended: S1 (Choosing AI Technology) then S3 (Managing AI)
**If you're an Agent Manager:** → Recommended: S3 (Managing AI) to learn your core skills
**If you're a Developer:** → Recommended: S2 (Understanding Agents) then S3 (Managing AI)

**Alternative paths:**
- Want to see more implementation details? → See economics case studies
- Ready to understand skills needed? → Go to Course 2: Skills

---

## Related Resources

**Glossary Terms:**
- Chief AI Officer
- AI Champion
- Agent Manager
- AI Agent Developer
- Level 4
- Rapid Iteration
- Context Engineering

**Case Studies:**
- HR Onboarding: Full Sarah + Marcus partnership story
- Sales Enablement: Full David + Priya partnership story
- Operations: Full Jennifer + Alex partnership story
- 7 additional detailed case studies in economics folder

**Templates:**
- Role assessment worksheet
- Team planning template
- 90-day action plan
