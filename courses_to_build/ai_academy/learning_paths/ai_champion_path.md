# Learning Path: AI Champion

**Target Audience:** AI Champions, transformation leads, innovation directors
**Total Time:** ~110 minutes (complete curriculum)
**Goal:** Master full AI transformation methodology from strategy to implementation

---

## Why This Path

As an AI Champion, you are responsible for:
- Leading AI transformation across multiple departments
- Making build-vs-buy decisions and evaluating solutions
- Building and managing teams (AI Champions, Agent Managers, Developers)
- Establishing transformation processes and best practices
- Measuring success and demonstrating ROI

**You need the complete picture** - strategy + implementation + organizational design.

This is the full curriculum. You'll understand both the "why" and the "how."

---

## Your Learning Journey

### Module 1: F1 - Five Levels Framework (20 min)

**Why you need this:** Foundation for transformation strategy

**What you'll learn:**
- The 5 levels of AI adoption in detail
- Why Level 3 fails (1-2 iterations/month → 70% reliability → abandonment)
- What defines Level 4 (10-20 iterations/day, 200+ total cycles to reach 95%+)
- Iteration economics: cost and speed of feedback loops
- How to map your organization's current state and path forward

**Your role application:**
- Assess which level each department currently operates at
- Identify departments trapped at Level 3 (external agency dependency)
- Build the case for Level 4 structure investment
- Set realistic timeline expectations with stakeholders

**Key questions you can now answer:**
- Why can't we just hire an external agency? (Iteration economics - they can only do 1-2 cycles/month)
- How long to reach production-ready? (6-10 weeks with Level 4 structure, never with Level 3)
- What's the difference between our failed automation and successful ones? (Iteration capability)

---

### Module 2: F2 - Organization Structure (18 min)

**Why you need this:** You're building and managing these teams

**What you'll learn:**
- Four key roles with detailed responsibilities: Chief AI Officer, AI Champions, Agent Managers, AI Agent Developers
- Why Agent Manager + Developer partnership is the Level 4 defining structure
- Real implementation stories across HR, Sales, Operations showing 200+ iteration patterns
- 3-phase transformation process with timelines and budgets
- Team sizing formulas and scaling patterns
- How to identify and promote Agent Manager candidates

**Your role application:**
- Design team structure for your organization
- Recruit and develop Agent Managers (promote domain experts)
- Hire or contract AI Agent Developers
- Establish Agent Manager + Developer pairing process
- Plan budgets and timelines for multiple departments
- Create career paths for Agent Manager role

**Key decisions you can now make:**
- How many Agent Managers do we need? (1 per major department + high-value processes)
- Hire external or promote internal for Agent Manager? (Promote - they know the processes)
- What's a realistic budget for 3-department transformation? (Use F2 formulas)
- How to structure Developer team? (1-2 Developers can support 5-8 Agent Managers)

---

### Module 3: S1 - Choosing AI Technology (18 min)

**Why you need this:** You're making or guiding all build-vs-buy decisions

**What you'll learn:**
- Four AI approaches with decision criteria: ML, Custom Agentic, Existing Tools (with/without data), No AI
- When existing tools are sufficient vs when custom builds are necessary
- Context engineering advantage: model quality, retrieval logic, interface flexibility, advanced capabilities
- Three Agentic solution categories with ROI ranges and use cases
- Hybrid strategy: layering generic tools, platform tools with data, and custom builds

**Your role application:**
- Evaluate each use case across departments using decision framework
- Assess vendor solutions for limitations (interface lock-in, model quality, capabilities)
- Build business cases for custom development with ROI projections
- Create portfolio strategy: which problems get existing tools, which get custom builds
- Negotiate with vendors armed with understanding of their limitations

**Key decisions you can now make:**
- Should Marketing use Notion AI or build custom? (Check 4 limitation factors)
- Is this a $99K/year opportunity (Category 1) or $246K/year (Category 2)? (Use solution category guide)
- Do we need ML or Agentic AI for this problem? (Predictions vs reasoning/workflows)
- What's our stack: Generic tools + Platform tools + Custom builds? (Hybrid strategy)

---

### Module 4: S2 - Understanding Agents (12 min)

**Why you need this:** You're evaluating solutions and educating stakeholders

**What you'll learn:**
- Four components of AI agents: LLM, Tools, Memory, Autonomy (missing components = missing capabilities)
- The agentic spectrum from chat to multi-agent orchestration
- Strategic evaluation framework (component check, integration depth, iteration capability)
- How to evaluate vendor claims with specific questions
- Red flags vs green flags in "agentic" solutions
- Current limitations of AI agents and when they're NOT the right solution

**Your role application:**
- Vet vendor solutions during procurement process
- Educate executives on what to look for in demos
- Train Agent Managers on what "agentic" actually means
- Set realistic expectations for AI capabilities and limitations
- Avoid buying solutions that are just "AI-labeled" chat interfaces

**Key conversations you can now lead:**
- Vendor demo debrief: "Here's what we should ask about their tool implementation..."
- Executive education: "Not all AI agents are the same - here's how to evaluate..."
- Stakeholder expectation-setting: "AI can do X extremely well, but struggles with Y because..."
- Team guidance: "This solution is missing the memory component, which means..."

---

### Module 5: S3 - Managing AI (25 min) **MOST CRITICAL**

**Why you need this:** This is the actual transformation work

**What you'll learn:**

**Part 1: The Management Shift**
- Reframe from managing people to managing people + AI
- Success factors: understanding, empathy, communication, quality standards, iteration
- Why domain experts (Agent Managers) can manage AI for their domain

**Part 2: Level 3.5 Tools**
- Cursor IDE, Claude Code for prototyping and productivity
- When non-technical teams can build alone vs involve developers
- Prototyping strategy before full development investment

**Part 3: Context Engineering Methodology** ⭐ Most Important
- 5-step methodology: Process Mapping → Data Identification → Source Mapping → Structure Definition → Validation
- Why you can't document all expertise upfront (iterative discovery)
- Real examples from HR (Onboarding), Sales (Call Analyzer), Marketing (Content Quality)
- Common patterns: tacit knowledge extraction, format structures (rubrics, examples, templates)
- Validation progression: 100% review → sampling → exception-only

**Part 4: Multi-Agentic Systems**
- When to break workflows into specialized subprocesses
- Sales Call Analyzer example (3 subprocesses with distinct requirements)
- Planning framework: Purpose, Tools, Workflow, Context, Output for each subprocess

**Part 5: Agent Manager vs Developer Scope**
- What Agent Managers can build with Level 3.5 tools
- When to involve developers (integrations, scale, multi-agentic, production deployment)
- The partnership model and why it enables rapid iteration

**Your role application:**
- Train Agent Managers on context engineering methodology
- Review and improve context quality across initiatives
- Establish validation processes and quality thresholds
- Decide which projects need Developer involvement
- Manage portfolio of: prototypes (Level 3.5), production builds (Level 4), and multi-agentic systems
- Track iteration velocity and accuracy progression across all initiatives

**Key responsibilities you can now execute:**
- **Guide Agent Managers** through their first context engineering project (5-step methodology)
- **Quality assurance** for context (review rubrics, examples, structure across departments)
- **Scope decisions** (Level 3.5 prototype vs full Developer build vs multi-agentic architecture)
- **Best practice sharing** (patterns from HR example apply to Sales, Marketing, etc.)
- **Iteration management** (ensure 10-20 cycles/day during active development, not 1-2/month)

---

## What You Can Do After This Path

**Strategic Leadership:**
- ✅ Build 3-year transformation roadmap across all departments
- ✅ Make informed build-vs-buy decisions for every use case
- ✅ Assess and vet vendor solutions during procurement
- ✅ Set realistic expectations with executives and board
- ✅ Identify which departments are ready vs need preparation

**Team Building & Management:**
- ✅ Design team structure: ratio of Champions, Agent Managers, Developers
- ✅ Recruit Agent Manager candidates (identify domain experts with documentation skills)
- ✅ Hire or contract AI Agent Developers with right skillsets
- ✅ Establish Agent Manager + Developer pairing process
- ✅ Create career paths and professional development for Agent Managers
- ✅ Train Agent Managers on context engineering methodology

**Transformation Execution:**
- ✅ Launch pilots in 3-5 departments simultaneously
- ✅ Review context engineering quality (rubrics, examples, structure)
- ✅ Track iteration velocity (10-20/day target during active development)
- ✅ Monitor accuracy progression (70% → 95% over 6-10 weeks)
- ✅ Establish validation processes and quality thresholds
- ✅ Decide when projects need multi-agentic architecture
- ✅ Manage portfolio: prototypes, production builds, scaling initiatives

**Measurement & Communication:**
- ✅ Track ROI across initiatives (time savings, quality improvements, user satisfaction)
- ✅ Report to executives: accuracy trends, iteration velocity, ROI realized vs projected
- ✅ Share best practices across Agent Managers (context patterns, validation strategies)
- ✅ Communicate wins and learnings to organization
- ✅ Build case studies for future investments

---

## Your First 90 Days as AI Champion

**Days 1-30: Foundation**

**Week 1-2: Assessment**
- Map current state: Which level is each department at?
- Identify existing AI initiatives: Which are succeeding vs stalling?
- Assess iteration capability: Internal teams or external agency dependencies?
- Interview department heads: What processes are painful, repetitive, or bottlenecked?

**Week 3-4: Planning**
- Choose 1-2 pilot departments (recommendation: HR + one other)
- Select specific use cases using S1 decision framework
- Identify Agent Manager candidates in pilot departments
- Draft budgets and timelines using F2 guidance
- Present plan to executives for approval

**Days 31-60: Team Building**

**Week 5-6: Recruitment**
- Promote or hire Agent Managers for pilot departments
- Hire or contract 1-2 AI Agent Developers
- Establish Agent Manager + Developer pairing
- Set up collaboration environment (co-located if possible)

**Week 7-8: Training**
- Train Agent Managers on context engineering (5-step methodology from S3)
- Introduce Developers to Agent Manager partnership model
- Set expectations: 10-20 iteration cycles/day during active development
- Define success metrics: iteration velocity, accuracy progression, ROI

**Days 61-90: Execution**

**Week 9-10: Launch**
- Agent Managers begin Step 1-2 (Process Mapping, Data Identification)
- Developers set up infrastructure and integration architecture
- First iteration cycles begin
- Track daily: how many feedback loops completed?

**Week 11-12: Iteration**
- Rapid iteration phase: 10-20 cycles/day
- Agent Managers refine context based on test results
- Review context quality: Are rubrics clear? Examples sufficient?
- Accuracy tracking: Monitor progression from 70% toward 95%

**Days 91+: Scale & Optimize**

- Validate: Move from 100% review → sampling → exception-only
- Measure ROI: Time savings, quality improvements, user satisfaction
- Document learnings: What context patterns work across departments?
- Plan next wave: 2-3 additional departments based on pilot success
- Share wins: Create case studies for organizational buy-in

---

## Common AI Champion Challenges & Solutions

**Challenge 1: Agent Manager candidates don't think they can do this (imposter syndrome)**

**Solution:**
- Emphasize it's NOT a technical role - it's process documentation
- Show them Module S3 Part 3 (context engineering examples from HR, Sales, Marketing)
- Start with Level 3.5 prototyping (Cursor, Claude Code) to build confidence
- Pair with Developer from day 1 (they're not alone)
- Celebrate small wins: first FAQ structured, first rubric created, first 80% accurate output

---

**Challenge 2: Developers want to build everything, gatekeep Agent Managers**

**Solution:**
- Educate Developers on Agent Manager + Developer partnership model (F2)
- Emphasize their role is enabling Agent Manager autonomy, not gatekeeping
- Show them S3 Part 5: Clear scope boundaries (what Agent Managers can build alone)
- Measure Developer success by Agent Manager productivity (not lines of code)
- Reframe: "Your job is to 10x the Agent Manager, not do all the work yourself"

---

**Challenge 3: Iteration velocity is slow (only 2-3 cycles/day instead of 10-20)**

**Solution:**
- Check co-location: Are Agent Manager + Developer sitting together or remote?
- Identify bottlenecks: What's slowing the feedback loop? (Deployment? Testing environment? Communication lag?)
- Simplify deployment: Can Agent Manager test changes themselves without waiting for Developer?
- Remove approval layers: Agent Manager should be able to update context and test immediately
- Review F1: Iteration economics - emphasize that speed IS the competitive advantage

---

**Challenge 4: Accuracy stuck at 80%, not reaching 95%+**

**Solution:**
- Review context quality with Agent Manager:
  - Are rubrics specific enough? (1-5 scale with clear definitions for each level)
  - Do we have sufficient examples? (Need 3-5 good, 3-5 bad, annotated)
  - Is structure hierarchical and cross-referenced?
- Check for missing tacit knowledge: What does Agent Manager "just know" that isn't documented?
- Add validation rules: How should AI escalate when uncertain?
- Increase iteration volume: May need more than 200 cycles for complex domains
- Review S3 Part 3: Compare to HR/Sales/Marketing examples - what's different?

---

**Challenge 5: Executives want instant results, don't understand 6-10 week timeline**

**Solution:**
- Show F1: Level 3 trap example (6 months → still not ready → abandoned)
- Explain 70% → 95% progression is NORMAL and requires 200+ iterations
- Reframe: "6-10 weeks to production-ready is FAST compared to traditional software (6-12 months)"
- Set interim milestones: Week 2 review (is context structure looking good?), Week 4 checkpoint (are we hitting 80%?)
- Share quick wins: Even at 80%, may be useful for human-in-loop scenarios
- Reference S1 ROI ranges: "$99K/year is worth 10-week investment"

---

**Challenge 6: Department heads don't want to "give up" staff to be Agent Managers**

**Solution:**
- Reframe as promotion/career development (not "giving up")
- Show ROI: Agent Manager role creates $99K-$246K/year value (more than their current role)
- Emphasize Agent Managers will 10x their department's impact (not just their own work)
- Offer backfill: Use savings from AI automation to hire replacement for their previous role
- Make it prestigious: Agent Manager is strategic role, not operational
- Reference F2: Real stories of HR/Sales/Ops transformations led by Agent Managers

---

## Collaboration with Other Roles

**With Chief AI Officer:**
- Report on: Transformation progress, ROI realized, challenges/blockers
- Request: Budget approvals, executive alignment, policy decisions
- Collaborate on: Multi-year roadmap, vendor relationships, organizational announcements

**With Agent Managers:**
- Train on: Context engineering methodology, quality standards, iteration best practices
- Review: Context quality (rubrics, examples, structure)
- Support: Remove blockers, facilitate Developer partnership, celebrate wins
- Measure: Iteration velocity, accuracy progression, time to production-ready

**With Developers:**
- Clarify: Scope boundaries (what Agent Managers build vs Developer builds)
- Establish: Rapid iteration processes, deployment automation, testing environments
- Guide: Multi-agentic architecture decisions, tool/platform choices
- Monitor: Are they enabling Agent Manager autonomy or gatekeeping?

**With Executives:**
- Educate: Iteration economics, realistic timelines, why internal teams beat agencies
- Report: ROI metrics, accuracy trends, transformation progress
- Propose: Next wave of departments, budget for scaling, vendor procurement
- Manage: Expectations (70% → 95% is normal, 6-10 weeks is realistic)

---

## Success Metrics for AI Champions

**Team Performance:**
- Iteration velocity: 10-20 cycles/day during active development per initiative
- Agent Manager productivity: Each Agent Manager launches 2-4 agents/year
- Developer leverage: Each Developer supports 5-8 Agent Managers
- Time to production: 6-10 weeks from kickoff to deployed solution

**Solution Quality:**
- Accuracy progression: 70% (Week 2) → 85% (Month 1) → 95%+ (Month 2-3)
- Context quality: Rubrics detailed, examples annotated, structure hierarchical
- Validation rigor: 100% review initially → exception-only within 2 months
- User satisfaction: 4.5+ / 5 rating from end users

**Business Impact:**
- ROI realized: Track actual vs projected (time savings, quality improvements)
- Coverage: % of target processes automated (goal: 80%+ of repetitive work)
- Adoption: % of employees actively using AI agents in their workflow
- Scalability: Number of departments successfully transformed

**Organizational Maturity:**
- Level progression: Movement from Level 1-2 → Level 4 across departments
- Best practices: Documented patterns reusable across Agent Managers
- Talent development: Agent Manager career path established, promotions happening
- Internal capability: Reduced external agency dependency over time

---

## Related Resources

**Essential Reading:**
- All modules F1, F2, S1, S2, S3 (your core curriculum)
- Economics case studies: 10 agent deployments with detailed ROI (`resources/economics/`)
- Use cases: Level 3 to 4 transformation examples (`resources/use_cases_level_3_to_4.md`)

**For Your Teams:**
- Agent Manager Path: Send to all Agent Manager candidates
- Developer Path: Send to AI Agent Developers
- Executive Path: Use for executive education and stakeholder alignment

**Community & Learning:**
- Join AI Champion peer groups (if available)
- Share learnings with other champions internally
- Build case study library of your organization's wins
